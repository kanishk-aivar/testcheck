import random
from time import sleep
import json
import datetime
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import undetected_chromedriver as uc
from bs4 import BeautifulSoup          # Add this for fallback parsing

PROXIES = []   # Leave empty or add proxies like "user:pass@host:port"

JSON_FILE = 'ai_overview_results_selenium.json'

try:
    with open(JSON_FILE, 'r', encoding='utf-8') as f:
        results = json.load(f)
except Exception:
    results = []

def make_chrome_options(proxy):
    chrome_options = Options()
    chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("--disable-infobars")
    chrome_options.add_argument("--disable-extensions")
    chrome_options.add_argument(
        "--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 12_3) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
    )
    if proxy:
        chrome_options.add_argument(f'--proxy-server=http://{proxy}')
    return chrome_options

def fallback_bs4_html_parse(page_html):
    """If normal selectors fail, do a soup search for blocks containing Gemini/SGE cues."""
    soup = BeautifulSoup(page_html, "html.parser")
    for div in soup.find_all("div"):
        t = div.get_text(separator="\n") or ""
        if (
            ("AI Overview" in t or "Gemini" in t or "SGE" in t or "AI-powered overview" in t)
            and len(t) > 40
        ):
            # Remove all script/style children
            [s.decompose() for s in div.find_all(["script", "style"])]
            return str(div), t
    return None, None

def get_overview_block(driver):
    # Try all known CSS selector patterns for 2024/2025 SGE/Gemini/AI Overview UI
    selectors = [
        'div[data-md="311"]',
        'div[data-attrid*="ai_overview"]',
        'div[aria-label*="AI Overview"]',
        'div[data-attrid*="sgx"]',
        'div[data-attrid*="synth"]',
        'div[class^="wDYxhc"]',
        'div[data-ved]',                # Sometimes the parent has this and contains the box at top of SERP
    ]
    for sel in selectors:
        try:
            elems = driver.find_elements(By.CSS_SELECTOR, sel)
            for el in elems:
                html = el.get_attribute("outerHTML")
                txt = el.text
                # Ensure it's a substantial block, with plausible SGE/Gemini cues, not just a geometry box
                if (
                    html and len(html) > 200 and
                    any(s in txt for s in ["AI Overview", "Gemini", "SGE", "AI-powered overview", "Generated by"])
                ):
                    return html, txt
        except Exception:
            continue
    # Fallback: HTML search for "AI Overview", "Gemini", etc. in divs
    return fallback_bs4_html_parse(driver.page_source)

def scrape_ai_overview(query):
    proxy = random.choice(PROXIES) if PROXIES else None
    chrome_options = make_chrome_options(proxy)
    driver = uc.Chrome(options=chrome_options, use_subprocess=True)
    result = {
        "searchQuery": query,
        "proxy": proxy,
        "extractedAt": datetime.datetime.now().isoformat(),
        "ai_html": None,
        "ai_text": None
    }
    try:
        url = f"https://www.google.com/search?q={query.replace(' ', '+')}&hl=en"
        driver.get(url)
        sleep(random.uniform(6, 11))
        # Note: CAPTCHAs will be missed in headless; you'll need 2captcha or manual solve if running non-headless
        if "recaptcha" in driver.page_source.lower() or "i'm not a robot" in driver.page_source.lower():
            print("CAPTCHA encountered! Skipping this run.")
            result["ai_text"] = "CAPTCHA encountered"
        else:
            ai_html, ai_txt = get_overview_block(driver)
            if ai_html:
                print(f"\nAI Overview found for: {query} (proxy: {proxy})")
                print(f"Summary snippet:\n{'-'*40}\n{ai_txt[:800]}{'...' if len(ai_txt)>800 else ''}\n{'-'*40}")
                result["ai_html"] = ai_html
                result["ai_text"] = ai_txt
            else:
                print(f"NO AI Overview found for: {query} (proxy: {proxy})")
                debugfile = f"debug_{query.replace(' ', '_')}.html"
                with open(debugfile, "w", encoding='utf-8') as f:
                    f.write(driver.page_source)
                print(f"Debug HTML of page saved as {debugfile}")
    except Exception as e:
        print(f"Error: {e}")
        result["ai_text"] = f"Error: {e}"
    finally:
        driver.quit()
    return result

def main():
    while True:
        user_query = input("\nEnter a Google query (or 'exit' to stop): ").strip()
        if user_query.lower() in ('exit', 'quit', ''):
            print("Goodbye!")
            break
        record = scrape_ai_overview(user_query)
        results.append(record)
        with open(JSON_FILE, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print("Result saved. Sleeping before next request...")
        sleep(random.uniform(10, 22))

if __name__ == "__main__":
    main()
